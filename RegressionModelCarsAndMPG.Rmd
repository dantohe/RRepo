---
title: "Regression Models: Cars And MPG"
author: "DA"
date: "May 27, 2016"
output: pdf_document
---
#Executive Summary

Scenario: you work for Motor Trend, a magazine about the automobile industry. Looking at a data set of a collection of cars, they are interested in exploring the relationship between a set of variables and miles per gallon (MPG) (outcome). They are particularly interested in the following two questions:  
- Is an automatic or manual transmission better for MPG?  
- Quantify the MPG difference between automatic and manual transmissions  

This brief analysis considers cars fuel economy and a set of variables, in particular the car transmission (automatic versus manual). We use mtcars dataset made available by Motor Trend Magazine.   

We perform exploratory data analysis followed by finding predictors for MPG. The first part of analysis looks into the variables and picks some and evaluates their performance as predictors for MPG. In the second part we use multivariable regression where we allow an automatic selection of the set of best predictors.

#Prerequsites
Loading the libraries and the dataset.  
```{r results='hide', message=FALSE, warning=FALSE}
library(ggplot2)
library(UsingR)
require(GGally)
library(relaimpo)
data(mtcars)
```


#The Data - performing data exploration
The mtcars dataset, data frame with 32 observations on 11 variables (source: https://stat.ethz.ch/R-manual/R-devel/library/datasets/html/mtcars.html).  

[, 1]	mpg	Miles/(US) gallon  
[, 2]	cyl	Number of cylinders  
[, 3]	disp	Displacement (cu.in.)  
[, 4]	hp	Gross horsepower  
[, 5]	drat	Rear axle ratio  
[, 6]	wt	Weight (1000 lbs)  
[, 7]	qsec	1/4 mile time  
[, 8]	vs	V/S  
[, 9]	am	Transmission (0 = automatic, 1 = manual)  
[,10]	gear	Number of forward gears  
[,11]	carb	Number of carburetors  

##MPG distribution
As MPG is the main subject of interest we are looking into how this variable is distributed using some normal probability plots.
```{r}
simple.eda(mtcars$mpg)
```
We see in the above plots that:  
- the cars within 15 to 25 mpg are more frequent (histogram)  
- the mpg is symmetrically distributed with a regular tale, as opposed to skewed (boxplot)  
- the QQ plot indicates that we can approximate this distribution as normal  

###Shapiro-Wilk Test - MPG distribution   
Using Shapiro-Wilk Normality Test and getting a p-value = 0.1229 which translates in the fact that we cannot reject  reject the NULL hypothesis that the samples came from a normal distribution.  

```{r}
shapiro.test(mtcars$mpg)
```

###Exploring correlations
We pick a few variables and look for correlations between them. We ignored displacement, horsepower as they correlate with cylinders. We are mostly into correlations with MPGs.

```{r}
cor(mtcars[,c("mpg", "cyl", "wt","am", "gear")])
```
We see a strong negative (-0.87) correlation between MPG and the weight of the car (as the car becomes heavier it gets lesser MPG). Number of gears doesn't seem to be an interesting variable.    
Another way to look into correlations:    
```{r}
cp1 = ggpairs(mtcars, columns =c("mpg", "cyl", "wt","am"),columnLabels = c("MPG", "Cylinders","Wight", "Transmission"), lower = list(
             continuous = "smooth",combo = "facetdensity", diag = NULL)
)
cp1
```

We have a correlation factor of -0.852 between MPG and the Number of Cylinders which we can interpret as a strong downhill linear relationship which makes sense as a greater number of cylinders means generally a bigger engine consuming more gas.  
MPG and transmission correlate with a coefficient of 0.6 which is a moderate positive relationship. The data set models the manual transmission as 1 and automatic as 0, hence one can say that a manual transmission tends to provide a better MPG.



###T-test - comparing the means of MPG, transmission and number of cylindres

```{r}
t.test(mtcars$mpg, mtcars$am, var.equal=TRUE, paired=FALSE)
t.test(mtcars$mpg, mtcars$cyl, var.equal=TRUE, paired=FALSE)
```

We get a very small p-value which translates in the fact that the difference in means is not by chance but indeed there is clear difference in these two populations. So we reject the NULL hypothesis: "these two samples have the same means."  


#Regression  Models
##Single Variable Models
Starting by building some simple (non multivariable) regression model: mpg function of cylinders, weight and transmission
```{r}
model.1 = lm(mpg~cyl, data = mtcars)
coef(model.1)
model.2 = lm(mpg~wt, data = mtcars)
coef(model.2)
model.3 = lm(mpg~am, data = mtcars)
coef(model.3)
```
We see intercepts of 37, 37 and 17 respectively. The slope is negative for the first two models and positive for the third that we interpret as follows:  
- for every additional cylinder we lose 2.9 MPGs  
- for every 1000 pounds of additional weight we lose 5.3 MPGs  
- manual transmission provides a gain of 7 MPGs  


##Residual Analysis
It is considered that residual standard error is a better approximation of the model goodness than the R-squared.
```{r}
summary(model.1)$sigma
summary(model.1)$r.squared
summary(model.2)$sigma
summary(model.2)$r.squared
summary(model.3)$sigma
summary(model.3)$r.squared
```
We see above the the second model (vehicle weight as independent variable) performs best as MPG predictor with a residual standard error of 3 and an R-squared of 0.75 while the third one (transmission) is the worst with an error of 4.9 and a R-squared of 0.36.  

##Plotting Residuals  
We plot as example the model using the weight as independent variable.    
```{r}
plot(mtcars$wt, resid(model.2), xlab = "Car Weight", ylab = "Residuals MPG", bg = "lightblue", col = "black", cex = 2, pch = 21,frame = FALSE)
abline(h = 0, lwd = 2)
for (i in 1 : length(mtcars$wt)) 
        lines(c(mtcars$wt[i], mtcars$wt[i]), c(resid(model.2)[i], 0), col = "red" , lwd = 2)
```

We see a pattern less plot.  

##Comparing the models  

We use Anova to compare the three models.   
```{r}
anova(model.1, model.2, model.3)
```
The second model with an RSS of 278 is the winner.

##Multivariable Regression  

###Selecting the Right Predictors 
Building a regression model using Backward Stepwise Regression (starting with all predictors and removes the ones that are not statistically significant).

```{r, results="hide"}
initial.model <- lm(mpg ~., data= mtcars)
best.model <- step(initial.model, direction = "both")
```

##Analyzing the selected predictors  

We are looking into the independent variables picked. 
```{r}
summary(best.model)
```
We see (p value) the weight of the car and qsec making a bigger difference than the transmission.  
We also calculate the relative importance of each variable using the relaimpo library.  
```{r}
calc.relimp(best.model)$lmg
```
We can find above the r-squared averaged over orderings among regressors - this time weight is again most important regressor. The transmission come in second followed by qsec.  
We can also plot the relative importance of each independent variable by bootstrapping using 500 samples.  
```{r}
boot <- boot.relimp(best.model, b = 500, rank = TRUE, diff = TRUE, rela = TRUE)
plot(booteval.relimp(boot,sort=TRUE))
```


###Sumarizing the best regression model
The most significant variables are identified as being:   
- the weight of the car (wt)   
- the 1/4 mile time (qsec)
The transmission seems to be of a lower importance as predictor of MPG.

We see a really small p-value (1.21e-11 much smaller than 0.05) meaning a good model.
We also see an decent R-squared: 0.8497 which translates to outcome variance explained by this model.
```{r}
summary(best.model)
m1 = lm(mpg ~ wt + disp + cyl+gear+am, data = mtcars);
anova(m1)
```


